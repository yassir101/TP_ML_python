{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9ec7a1-9763-41fe-8bd9-fb11dc9eb614",
   "metadata": {},
   "source": [
    "# Rappel  \n",
    "(dans le cas d'une utilisation sur votre poste personnel)\n",
    "Avant de commencer, assurez-vous d‚Äôavoir Scikit-learn install√© (de pr√©f√©rence dans un environnement virtuel en utilisant conda) :\n",
    "pip install scikit-learn\n",
    "\n",
    "sinon, √† l'insa : \n",
    "\n",
    "``` $ source /opt/venv/stpi-m8/bin/activate``` \n",
    "\n",
    "``` $ python -m ipykernel install --user --name M8``` \n",
    "\n",
    "``` $ jupyter notebook``` \n",
    "\n",
    "Nous utilisons un notebook Python. Cet outil est int√©ressant pour prototyper rapidement du code mais peut s'av√©rer difficile (car les cellules peuvent √™tre lanc√©es dans un ordre arbitraire et provoquer des effets de bord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf4299f-a072-46cc-b7c2-27a85bb6214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import n√©cessaires pour ce TP \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4658cf-0024-4086-be09-15619e929da1",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation de pipeline et validation crois√©e\n",
    "\n",
    "Dans scikit-learn, un Pipeline est un moyen de cha√Æner plusieurs √©tapes de pr√©traitement et de mod√©lisation dans un processus unique et automatis√©. \n",
    "\n",
    "- Facilite l'exp√©rimentation : au lieu d'appliquer s√©par√©ment la standardisation, la r√©duction de dimension et le mod√®le, tout est g√©r√© dans un m√™me flux de travail.\n",
    "- √âvite la fuite de donn√©es : chaque transformation est appliqu√©e uniquement sur l‚Äôensemble d‚Äôentra√Ænement, puis utilis√©e sur l‚Äôensemble de test sans biais.\n",
    "-  Compatible avec GridSearchCV : permet d‚Äôoptimiser tous les param√®tres du pipeline en une seule recherche.\n",
    "-  Code plus propre et structur√© : plus lisible et maintenable.\n",
    "\n",
    "En pratique, un pipeline est compos√© d'une suite d'objets (Transformater et Estimator), chacun appliqu√© dans l'ordre. Les trois points √† retenir : \n",
    "\n",
    "- Toutes les √©tapes sauf la derni√®re doivent √™tre des transformateurs (avoir une m√©thode .fit_transform()).\n",
    "- La derni√®re √©tape doit √™tre un estimateur (.fit() et .predict()).\n",
    "- Le pipeline se comporte ensuite comme un estimateur.\n",
    "\n",
    "0n pourra faire une validation crois√©e sur le pipeline et chercher la meilleure combinaison d'hyperparam√®tres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8591bdcf-bde2-4a39-8c25-54592ecb7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des donn√©es : (1000, 20)\n",
      "Accuracy du pipeline : 0.77\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77        96\n",
      "           1       0.81      0.72      0.76       104\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.76       200\n",
      "weighted avg       0.77      0.77      0.76       200\n",
      "\n",
      "Meilleurs param√®tres : {'pca__n_components': 5, 'svm__C': 0.1}\n",
      "Accuracy avec les meilleurs param√®tres : 0.82\n",
      "\n",
      "Rapport de classification (mod√®le optimis√©) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        96\n",
      "           1       0.81      0.85      0.83       104\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.82      0.82       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# G√©n√©ration du dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=5, \n",
    "                           n_redundant=5, random_state=42)\n",
    "\n",
    "# S√©paration en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage des dimensions\n",
    "print(f\"Dimensions des donn√©es : {X.shape}\")\n",
    "\n",
    "# D√©finition du pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Normalisation\n",
    "    ('pca', PCA(n_components=2)),  # R√©duction de dimension\n",
    "    ('svm', SVC(kernel='linear'))   # Classificateur SVM\n",
    "])\n",
    "\n",
    "# Entra√Ænement du pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Pr√©diction\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy du pipeline : {accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# D√©finition des hyperparam√®tres √† optimiser\n",
    "param_grid = {\n",
    "    'pca__n_components': [3, 5, 10, 15],  \n",
    "    'svm__C': [0.1, 1, 10]  \n",
    "}\n",
    "\n",
    "# Recherche du meilleur mod√®le\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1) #validation crois√©e √† 5 folds\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs param√®tres trouv√©s\n",
    "print(\"Meilleurs param√®tres :\", grid_search.best_params_) #donne le meilleur estimateur\n",
    "\n",
    "# √âvaluation sur le test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Affichage des scores\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Accuracy avec les meilleurs param√®tres : {best_accuracy:.2f}\")\n",
    "print(\"\\nRapport de classification (mod√®le optimis√©) :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "#ici le meilleur param√®tre est SVM avec une accuracy score de 0.1 et selection de 5 composantes\n",
    "#Avec SVM l'accuracy est 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69057267-6246-4c3c-a665-98a565daf8bc",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "\n",
    "Dans ce TP, nous allons :\n",
    "\n",
    "    - Utiliser un jeu de donn√©es r√©el pour tester un pipeline de classification.\n",
    "    - Impl√©menter un noyau personnalis√© pour l'interfacer avec SVC.\n",
    "    - Construire plusieurs pipelines avec ACP et diff√©rents noyaux (lin√©aire, RBF, personnalis√©).\n",
    "    - Optimiser les hyperparam√®tres (C, n_components) avec GridSearchCV.\n",
    "    - Comparer les performances et analyser l'impact du noyau et de l'ACP.\n",
    "\n",
    "Documentation utile :\n",
    "\n",
    "    SVM - Support Vector Machine\n",
    "    PCA - Analyse en Composantes Principales\n",
    "    Pipeline\n",
    "    GridSearchCV - Optimisation des hyperparam√®tres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4aee6-3fb7-40df-9ed1-6a1fb512032b",
   "metadata": {},
   "source": [
    "# Chargement et Pr√©paration des Donn√©es\n",
    "\n",
    "Nous allons travailler sur le dataset Breast Cancer, qui contient :\n",
    "\n",
    "    30 caract√©ristiques sur les tumeurs.\n",
    "    2 classes (b√©nin ou malin).\n",
    "\n",
    "- Chargez le dataset et effectuez un split train/test (80% train, 20% test) (on utilisera `train_test_split`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f05b40-e614-45ea-8329-5292e5af37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom des features : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Classes : ['malignant' 'benign']\n",
      "Dimensions des donn√©es : (569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des donn√©es\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "\n",
    "feature_names= data.feature_names\n",
    "# Affichage des caract√©ristiques\n",
    "print(\"Nom des features :\", data.feature_names)\n",
    "print(\"Classes :\", data.target_names)\n",
    "print(\"Dimensions des donn√©es :\", X.shape)\n",
    "\n",
    "# S√©paration en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90bd59-274d-4154-93db-0637d8517883",
   "metadata": {},
   "source": [
    "# Impact de la standardisation\n",
    "\n",
    "On se concentre sur les feature suivantes : 0, 5, 10, 15, 20, 25\n",
    "\n",
    "- afficher leur distribution (via un histogramme) avant et apr√®s standardisation\n",
    "\n",
    "\n",
    "Pour aller plus loin, on pourra se r√©f√©rer √† \n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#plot-all-scaling-standard-scaler-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57444aa9-3a70-40b2-9743-73eba5b83b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üîπ Normalisation avec StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# application sur les donn√©es de donn√©es\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_scaled = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# affichage des histogrammes avant/apr√®s \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].hist(X_train[:,0], bins=20)\n",
    "axs[1].hist(X_train_scaled[:,0], bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5a785-8523-4dcb-a022-cef94cd589cb",
   "metadata": {},
   "source": [
    "# Impl√©mentation d‚Äôun Noyau Personnalis√©\n",
    "\n",
    "Un noyau SVM permet de transformer l'espace des donn√©es. Nous allons coder dans une fonctione le noyau hybride (entre RBF et polynomial) :\n",
    "\n",
    "$\n",
    "K(x, y) = \\exp\\left(-\\gamma ||x - y||^2\\right) + \\alpha (x \\cdot y + 1)^d\n",
    "$\n",
    "\n",
    "On utilisera : $ \\gamma = 0.3$, $ \\alpha = 0.2 $ et $d = 2$ \n",
    "\n",
    "Comme nous allons l'utiliser dans un SVM, On pourra regarder la documentation : \n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afdf958c-faec-4fd1-891d-c19898003da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kernel(X, Y):\n",
    "    \"\"\"Noyau hybride : gaussien + polynomiale.\"\"\"\n",
    "    gamma = 0.3  # Contr√¥le la largeur du noyau gaussien\n",
    "    alpha = 0.2  # Pond√©ration du terme polynomial\n",
    "    d = 2  # Degr√© du polyn√¥me\n",
    "\n",
    "    # a compl√©ter \n",
    "    # rbf_svc = svm.SVC(kernel='rbf',gamma = gamma).fit(X, Y)\n",
    "    # polynomial_svc = svm.SVC(kernel='polynomial',degree = d,coef0 = 1).fit(X,Y)\n",
    "    # return rbf_svc + alpha * polynomial_svc\n",
    "    \n",
    "    #correction \n",
    "    euclidian_dist = np.sum((X[:,np.newaxis] - Y[np.newaxis,:])**2 , axis = 2)\n",
    "    gaussian_term = np.exp(-gamma * euclidiant_dist)\n",
    "    polynomial_term = alpha * (np.dot(X,Y.T) + 1)**d\n",
    "    \n",
    "    return gaussian_term + polynomial_term\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057c29d-8312-461b-9cdc-517405352540",
   "metadata": {},
   "source": [
    "# Cr√©ation des Pipelines\n",
    "\n",
    "A l'int√©rieur d'une pipeline, nous allons comparer trois mod√®les :\n",
    "\n",
    "    SVM Lin√©aire\n",
    "    SVM avec noyau rbf\n",
    "    SVM avec notre noyau personnalis√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "544cfd2d-0cba-4a78-851a-1f42eebe29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline avec SVM Lin√©aire\n",
    "pipeline_linear = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=2)), \n",
    "    ('svm', SVC(kernel='linear'))   # Classificateur SVM lin√©aire\n",
    "])\n",
    "\n",
    "# Pipeline avec SVM RBF\n",
    "pipeline_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('svm', SVC(kernel='rbf'))   # Classificateur SVM RBF\n",
    "])\n",
    "# Pipeline avec Noyau Personnalis√©\n",
    "pipeline_custom = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('svm', SVC(kernel=custom_kernel))   # Classificateur SVM noyau personnalis√©\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a91f0-80ef-46df-a060-ac66cf5382ba",
   "metadata": {},
   "source": [
    "# S√©lection d'hyperparam√®tres par validation crois√©e\n",
    "\n",
    "Nous allons chercher les meilleures valeurs de C et n_components via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e6514ae-2bbe-49b2-9e1c-7970b095b3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 105 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n105 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 250, in fit\n    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 310, in _dense_fit\n    X = self._compute_kernel(X)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 508, in _compute_kernel\n    kernel = self.kernel(X, self.__Xfit)\n  File \"/tmp/ipykernel_3466/2306021962.py\", line 14, in custom_kernel\nNameError: name 'euclidiant_dist' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m grid_svm_linear\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m grid_svm_rbf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgrid_custom_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Affichage des meilleurs param√®tres\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeilleurs param√®tres (SVM Lin√©aire) :\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_svm_linear\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 105 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n105 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 250, in fit\n    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 310, in _dense_fit\n    X = self._compute_kernel(X)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 508, in _compute_kernel\n    kernel = self.kernel(X, self.__Xfit)\n  File \"/tmp/ipykernel_3466/2306021962.py\", line 14, in custom_kernel\nNameError: name 'euclidiant_dist' is not defined\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'pca__n_components': [2, 5, 10, 15, 20, 25, 30],  \n",
    "    'svm__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# GridSearch pour chaque mod√®le\n",
    "grid_svm_linear = GridSearchCV(pipeline_linear, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm_rbf = GridSearchCV(pipeline_rbf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_custom_kernel =GridSearchCV(pipeline_custom, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entra√Ænement des mod√®les\n",
    "grid_svm_linear.fit(X_train, y_train)\n",
    "grid_svm_rbf.fit(X_train, y_train)\n",
    "grid_custom_kernel.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs param√®tres\n",
    "print(\"Meilleurs param√®tres (SVM Lin√©aire) :\", grid_svm_linear.best_params_)\n",
    "print(\"Meilleurs param√®tres (SVM RBF) :\", grid_svm_rbf.best_params_)\n",
    "print(\"Meilleurs param√®tres (Noyau Personnalis√©) :\", grid_custom_kernel.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f6c78-e6f5-4126-a5c6-3a162c1c76d7",
   "metadata": {},
   "source": [
    "# Performances en test\n",
    "\n",
    "Une fois les pipeline entrain√©s, on les compare sur les donn√©es de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be84803-eed0-40cd-a30b-86b92132d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©dictions\n",
    "y_pred_linear = grid_svm_linear.best_estimator_.predict(X_test)\n",
    "y_pred_rbf = grid_svm_rbf.best_estimator_.predict(X_test)\n",
    "y_pred_custom = grid_custom_kernel.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calcul du F1-score\n",
    "\n",
    "\n",
    "# Rapport de classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce56fc2-6fa0-40de-8413-c6e1f4e68305",
   "metadata": {},
   "source": [
    "# Pour aller plus loin\n",
    "\n",
    "Nous allons impl√©menter une ACP pour pouvoir s'interfacer avec sklearn.\n",
    "\n",
    "Pour rappel, voici les diff√©rentes √©tapes d'une ACP \n",
    "\n",
    "    Centrer les donn√©es : Soustraire la moyenne de chaque variable.\n",
    "    Calculer la matrice de covariance.\n",
    "    Effectuer la d√©composition en valeurs propres.\n",
    "    Ordonner les composantes par variance d√©croissante.\n",
    "    Projeter les donn√©es sur les nouvelles dimensions.\n",
    "\n",
    "- Impl√©menter l'ACP (avec les interfaces ad√©quates)\n",
    "- Int√©grer votre ACP dans un pipeline (SVM lin√©aire) et comparer avec les r√©sultats pr√©c√©dents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a3be8-dfc6-403c-b9e3-635cdac5130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        \"\"\"\n",
    "        Initialise l'ACP personnalis√©e.\n",
    "        :param n_components: Nombre de composantes principales √† conserver.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.components_ = None\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Calcule les composantes principales √† partir des donn√©es.\n",
    "        :param X: Matrice de donn√©es (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        # üîπ 1. Centrage des donn√©es\n",
    "\n",
    "        # üîπ 2. Calcul de la matrice de covariance\n",
    "\n",
    "        # üîπ 3. D√©composition en valeurs propres\n",
    "\n",
    "        # üîπ 4. Trier les valeurs propres (ordre d√©croissant)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Projette les donn√©es sur les axes des composantes principales.\n",
    "        :param X: Matrice de donn√©es (n_samples, n_features)\n",
    "        :return: X transform√© (n_samples, n_components)\n",
    "        \"\"\"\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Combine fit et transform pour appliquer l'ACP en une seule √©tape.\n",
    "        \"\"\"\n",
    "        return self.fit(X).transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086446b-0d86-46c9-b23c-a6d5e78fa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline avec SVM Lin√©aire avec PCA custom \n",
    "pipeline_svm_customPCA = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('CustomPCA', CustomPCA(n_components=10)),\n",
    "    ('svm', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M8",
   "language": "python",
   "name": "m8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
