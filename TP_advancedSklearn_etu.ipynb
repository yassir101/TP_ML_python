{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9ec7a1-9763-41fe-8bd9-fb11dc9eb614",
   "metadata": {},
   "source": [
    "# Rappel  \n",
    "(dans le cas d'une utilisation sur votre poste personnel)\n",
    "Avant de commencer, assurez-vous d’avoir Scikit-learn installé (de préférence dans un environnement virtuel en utilisant conda) :\n",
    "pip install scikit-learn\n",
    "\n",
    "sinon, à l'insa : \n",
    "\n",
    "``` $ source /opt/venv/stpi-m8/bin/activate``` \n",
    "\n",
    "``` $ python -m ipykernel install --user --name M8``` \n",
    "\n",
    "``` $ jupyter notebook``` \n",
    "\n",
    "Nous utilisons un notebook Python. Cet outil est intéressant pour prototyper rapidement du code mais peut s'avérer difficile (car les cellules peuvent être lancées dans un ordre arbitraire et provoquer des effets de bord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf4299f-a072-46cc-b7c2-27a85bb6214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nécessaires pour ce TP \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer, make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4658cf-0024-4086-be09-15619e929da1",
   "metadata": {},
   "source": [
    "# Exemple d'utilisation de pipeline et validation croisée\n",
    "\n",
    "Dans scikit-learn, un Pipeline est un moyen de chaîner plusieurs étapes de prétraitement et de modélisation dans un processus unique et automatisé. \n",
    "\n",
    "- Facilite l'expérimentation : au lieu d'appliquer séparément la standardisation, la réduction de dimension et le modèle, tout est géré dans un même flux de travail.\n",
    "- Évite la fuite de données : chaque transformation est appliquée uniquement sur l’ensemble d’entraînement, puis utilisée sur l’ensemble de test sans biais.\n",
    "-  Compatible avec GridSearchCV : permet d’optimiser tous les paramètres du pipeline en une seule recherche.\n",
    "-  Code plus propre et structuré : plus lisible et maintenable.\n",
    "\n",
    "En pratique, un pipeline est composé d'une suite d'objets (Transformater et Estimator), chacun appliqué dans l'ordre. Les trois points à retenir : \n",
    "\n",
    "- Toutes les étapes sauf la dernière doivent être des transformateurs (avoir une méthode .fit_transform()).\n",
    "- La dernière étape doit être un estimateur (.fit() et .predict()).\n",
    "- Le pipeline se comporte ensuite comme un estimateur.\n",
    "\n",
    "0n pourra faire une validation croisée sur le pipeline et chercher la meilleure combinaison d'hyperparamètres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8591bdcf-bde2-4a39-8c25-54592ecb7340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions des données : (1000, 20)\n",
      "Accuracy du pipeline : 0.77\n",
      "\n",
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77        96\n",
      "           1       0.81      0.72      0.76       104\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.76       200\n",
      "weighted avg       0.77      0.77      0.76       200\n",
      "\n",
      "Meilleurs paramètres : {'pca__n_components': 5, 'svm__C': 0.1}\n",
      "Accuracy avec les meilleurs paramètres : 0.82\n",
      "\n",
      "Rapport de classification (modèle optimisé) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        96\n",
      "           1       0.81      0.85      0.83       104\n",
      "\n",
      "    accuracy                           0.82       200\n",
      "   macro avg       0.82      0.82      0.82       200\n",
      "weighted avg       0.82      0.82      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Génération du dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=5, \n",
    "                           n_redundant=5, random_state=42)\n",
    "\n",
    "# Séparation en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage des dimensions\n",
    "print(f\"Dimensions des données : {X.shape}\")\n",
    "\n",
    "# Définition du pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),   # Normalisation\n",
    "    ('pca', PCA(n_components=2)),  # Réduction de dimension\n",
    "    ('svm', SVC(kernel='linear'))   # Classificateur SVM\n",
    "])\n",
    "\n",
    "# Entraînement du pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy du pipeline : {accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Définition des hyperparamètres à optimiser\n",
    "param_grid = {\n",
    "    'pca__n_components': [3, 5, 10, 15],  \n",
    "    'svm__C': [0.1, 1, 10]  \n",
    "}\n",
    "\n",
    "# Recherche du meilleur modèle\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1) #validation croisée à 5 folds\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres trouvés\n",
    "print(\"Meilleurs paramètres :\", grid_search.best_params_) #donne le meilleur estimateur\n",
    "\n",
    "# Évaluation sur le test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Affichage des scores\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Accuracy avec les meilleurs paramètres : {best_accuracy:.2f}\")\n",
    "print(\"\\nRapport de classification (modèle optimisé) :\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "#ici le meilleur paramètre est SVM avec une accuracy score de 0.1 et selection de 5 composantes\n",
    "#Avec SVM l'accuracy est 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69057267-6246-4c3c-a665-98a565daf8bc",
   "metadata": {},
   "source": [
    "# Objectifs\n",
    "\n",
    "Dans ce TP, nous allons :\n",
    "\n",
    "    - Utiliser un jeu de données réel pour tester un pipeline de classification.\n",
    "    - Implémenter un noyau personnalisé pour l'interfacer avec SVC.\n",
    "    - Construire plusieurs pipelines avec ACP et différents noyaux (linéaire, RBF, personnalisé).\n",
    "    - Optimiser les hyperparamètres (C, n_components) avec GridSearchCV.\n",
    "    - Comparer les performances et analyser l'impact du noyau et de l'ACP.\n",
    "\n",
    "Documentation utile :\n",
    "\n",
    "    SVM - Support Vector Machine\n",
    "    PCA - Analyse en Composantes Principales\n",
    "    Pipeline\n",
    "    GridSearchCV - Optimisation des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4aee6-3fb7-40df-9ed1-6a1fb512032b",
   "metadata": {},
   "source": [
    "# Chargement et Préparation des Données\n",
    "\n",
    "Nous allons travailler sur le dataset Breast Cancer, qui contient :\n",
    "\n",
    "    30 caractéristiques sur les tumeurs.\n",
    "    2 classes (bénin ou malin).\n",
    "\n",
    "- Chargez le dataset et effectuez un split train/test (80% train, 20% test) (on utilisera `train_test_split`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f05b40-e614-45ea-8329-5292e5af37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom des features : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Classes : ['malignant' 'benign']\n",
      "Dimensions des données : (569, 30)\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "\n",
    "feature_names= data.feature_names\n",
    "# Affichage des caractéristiques\n",
    "print(\"Nom des features :\", data.feature_names)\n",
    "print(\"Classes :\", data.target_names)\n",
    "print(\"Dimensions des données :\", X.shape)\n",
    "\n",
    "# Séparation en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90bd59-274d-4154-93db-0637d8517883",
   "metadata": {},
   "source": [
    "# Impact de la standardisation\n",
    "\n",
    "On se concentre sur les feature suivantes : 0, 5, 10, 15, 20, 25\n",
    "\n",
    "- afficher leur distribution (via un histogramme) avant et après standardisation\n",
    "\n",
    "\n",
    "Pour aller plus loin, on pourra se référer à \n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#plot-all-scaling-standard-scaler-section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57444aa9-3a70-40b2-9743-73eba5b83b0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 🔹 Normalisation avec StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# application sur les données de données\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pipeline.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_scaled = pipeline.predict(X_test_scaled)\n",
    "\n",
    "# affichage des histogrammes avant/après \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "axs[0].hist(X_train[:,0], bins=20)\n",
    "axs[1].hist(X_train_scaled[:,0], bins=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a5a785-8523-4dcb-a022-cef94cd589cb",
   "metadata": {},
   "source": [
    "# Implémentation d’un Noyau Personnalisé\n",
    "\n",
    "Un noyau SVM permet de transformer l'espace des données. Nous allons coder dans une fonctione le noyau hybride (entre RBF et polynomial) :\n",
    "\n",
    "$\n",
    "K(x, y) = \\exp\\left(-\\gamma ||x - y||^2\\right) + \\alpha (x \\cdot y + 1)^d\n",
    "$\n",
    "\n",
    "On utilisera : $ \\gamma = 0.3$, $ \\alpha = 0.2 $ et $d = 2$ \n",
    "\n",
    "Comme nous allons l'utiliser dans un SVM, On pourra regarder la documentation : \n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afdf958c-faec-4fd1-891d-c19898003da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_kernel(X, Y):\n",
    "    \"\"\"Noyau hybride : gaussien + polynomiale.\"\"\"\n",
    "    gamma = 0.3  # Contrôle la largeur du noyau gaussien\n",
    "    alpha = 0.2  # Pondération du terme polynomial\n",
    "    d = 2  # Degré du polynôme\n",
    "\n",
    "    # a compléter \n",
    "    # rbf_svc = svm.SVC(kernel='rbf',gamma = gamma).fit(X, Y)\n",
    "    # polynomial_svc = svm.SVC(kernel='polynomial',degree = d,coef0 = 1).fit(X,Y)\n",
    "    # return rbf_svc + alpha * polynomial_svc\n",
    "    \n",
    "    #correction \n",
    "    euclidian_dist = np.sum((X[:,np.newaxis] - Y[np.newaxis,:])**2 , axis = 2)\n",
    "    gaussian_term = np.exp(-gamma * euclidiant_dist)\n",
    "    polynomial_term = alpha * (np.dot(X,Y.T) + 1)**d\n",
    "    \n",
    "    return gaussian_term + polynomial_term\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057c29d-8312-461b-9cdc-517405352540",
   "metadata": {},
   "source": [
    "# Création des Pipelines\n",
    "\n",
    "A l'intérieur d'une pipeline, nous allons comparer trois modèles :\n",
    "\n",
    "    SVM Linéaire\n",
    "    SVM avec noyau rbf\n",
    "    SVM avec notre noyau personnalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "544cfd2d-0cba-4a78-851a-1f42eebe29a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline avec SVM Linéaire\n",
    "pipeline_linear = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('pca', PCA(n_components=2)), \n",
    "    ('svm', SVC(kernel='linear'))   # Classificateur SVM linéaire\n",
    "])\n",
    "\n",
    "# Pipeline avec SVM RBF\n",
    "pipeline_rbf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('svm', SVC(kernel='rbf'))   # Classificateur SVM RBF\n",
    "])\n",
    "# Pipeline avec Noyau Personnalisé\n",
    "pipeline_custom = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('svm', SVC(kernel=custom_kernel))   # Classificateur SVM noyau personnalisé\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91a91f0-80ef-46df-a060-ac66cf5382ba",
   "metadata": {},
   "source": [
    "# Sélection d'hyperparamètres par validation croisée\n",
    "\n",
    "Nous allons chercher les meilleures valeurs de C et n_components via GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e6514ae-2bbe-49b2-9e1c-7970b095b3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 105 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n105 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 250, in fit\n    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 310, in _dense_fit\n    X = self._compute_kernel(X)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 508, in _compute_kernel\n    kernel = self.kernel(X, self.__Xfit)\n  File \"/tmp/ipykernel_3466/2306021962.py\", line 14, in custom_kernel\nNameError: name 'euclidiant_dist' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m grid_svm_linear\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     14\u001b[0m grid_svm_rbf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgrid_custom_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Affichage des meilleurs paramètres\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeilleurs paramètres (SVM Linéaire) :\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_svm_linear\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    945\u001b[0m     )\n\u001b[0;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 105 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n105 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/pipeline.py\", line 475, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 250, in fit\n    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 310, in _dense_fit\n    X = self._compute_kernel(X)\n  File \"/opt/venv/stpi-m8-250121/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 508, in _compute_kernel\n    kernel = self.kernel(X, self.__Xfit)\n  File \"/tmp/ipykernel_3466/2306021962.py\", line 14, in custom_kernel\nNameError: name 'euclidiant_dist' is not defined\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'pca__n_components': [2, 5, 10, 15, 20, 25, 30],  \n",
    "    'svm__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# GridSearch pour chaque modèle\n",
    "grid_svm_linear = GridSearchCV(pipeline_linear, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_svm_rbf = GridSearchCV(pipeline_rbf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_custom_kernel =GridSearchCV(pipeline_custom, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Entraînement des modèles\n",
    "grid_svm_linear.fit(X_train, y_train)\n",
    "grid_svm_rbf.fit(X_train, y_train)\n",
    "grid_custom_kernel.fit(X_train, y_train)\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(\"Meilleurs paramètres (SVM Linéaire) :\", grid_svm_linear.best_params_)\n",
    "print(\"Meilleurs paramètres (SVM RBF) :\", grid_svm_rbf.best_params_)\n",
    "print(\"Meilleurs paramètres (Noyau Personnalisé) :\", grid_custom_kernel.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f6c78-e6f5-4126-a5c6-3a162c1c76d7",
   "metadata": {},
   "source": [
    "# Performances en test\n",
    "\n",
    "Une fois les pipeline entrainés, on les compare sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be84803-eed0-40cd-a30b-86b92132d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "y_pred_linear = grid_svm_linear.best_estimator_.predict(X_test)\n",
    "y_pred_rbf = grid_svm_rbf.best_estimator_.predict(X_test)\n",
    "y_pred_custom = grid_custom_kernel.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calcul du F1-score\n",
    "\n",
    "\n",
    "# Rapport de classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce56fc2-6fa0-40de-8413-c6e1f4e68305",
   "metadata": {},
   "source": [
    "# Pour aller plus loin\n",
    "\n",
    "Nous allons implémenter une ACP pour pouvoir s'interfacer avec sklearn.\n",
    "\n",
    "Pour rappel, voici les différentes étapes d'une ACP \n",
    "\n",
    "    Centrer les données : Soustraire la moyenne de chaque variable.\n",
    "    Calculer la matrice de covariance.\n",
    "    Effectuer la décomposition en valeurs propres.\n",
    "    Ordonner les composantes par variance décroissante.\n",
    "    Projeter les données sur les nouvelles dimensions.\n",
    "\n",
    "- Implémenter l'ACP (avec les interfaces adéquates)\n",
    "- Intégrer votre ACP dans un pipeline (SVM linéaire) et comparer avec les résultats précédents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a3be8-dfc6-403c-b9e3-635cdac5130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomPCA(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "        \"\"\"\n",
    "        Initialise l'ACP personnalisée.\n",
    "        :param n_components: Nombre de composantes principales à conserver.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.components_ = None\n",
    "        self.mean_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Calcule les composantes principales à partir des données.\n",
    "        :param X: Matrice de données (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        # 🔹 1. Centrage des données\n",
    "\n",
    "        # 🔹 2. Calcul de la matrice de covariance\n",
    "\n",
    "        # 🔹 3. Décomposition en valeurs propres\n",
    "\n",
    "        # 🔹 4. Trier les valeurs propres (ordre décroissant)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Projette les données sur les axes des composantes principales.\n",
    "        :param X: Matrice de données (n_samples, n_features)\n",
    "        :return: X transformé (n_samples, n_components)\n",
    "        \"\"\"\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Combine fit et transform pour appliquer l'ACP en une seule étape.\n",
    "        \"\"\"\n",
    "        return self.fit(X).transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086446b-0d86-46c9-b23c-a6d5e78fa8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline avec SVM Linéaire avec PCA custom \n",
    "pipeline_svm_customPCA = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('CustomPCA', CustomPCA(n_components=10)),\n",
    "    ('svm', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M8",
   "language": "python",
   "name": "m8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
